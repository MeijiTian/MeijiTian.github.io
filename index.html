<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Xuanyu Tian</title> <meta name="author" content="Xuanyu Tian"/> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="/assets/img/button.png"/> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://meijitian.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <body> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="nav-item "> <a class="nav-link" href="/friend/">Friends</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Xuanyu</span> Tian (田烜宇) </h1> <p class="desc"></p> </header> <article> <div class="profile float-right"> <figure> <picture> <img src="/assets/img/bio_txy_1.jpg" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="bio_txy_1.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="social"> <div class="contact-icons" style="font-size: 3em;"> <a href="mailto:%74%69%61%6E%78%79@%73%68%61%6E%67%68%61%69%74%65%68.%65%64%75.%63%6E" title="email"><i class="fas fa-envelope"></i></a> <a href="https://orcid.org/0009-0009-6724-373X" title="ORCID" target="_blank" rel="noopener noreferrer"><i class="ai ai-orcid"></i></a> <a href="https://scholar.google.com/citations?user=Ul4AAAAJ" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/meijitian" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a> </div> <div class="contact-note"> Feel free to find me in any way you like :) </div> </div> </div> <div class="clearfix"> <p>I am a 4-th year Ph.D. candicate in <a href="https://smilelab.com.cn" target="_blank" rel="noopener noreferrer">SMILE Lab<img class="emoji" title=":smiley:" alt=":smiley:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f603.png" height="20" width="20"></a> at <a href="https://www.shanghaitech.edu.cn" target="_blank" rel="noopener noreferrer">ShanghaiTech University</a> (Shanghai, China), advised by Prof. <a href="https://scholar.google.com/citations?user=gIE0JTAAAAAJ&amp;hl" target="_blank" rel="noopener noreferrer">Yuyao Zhang</a>. Before that, I received my B.E. degree of Computer Science and Technology from Wuhan University of Technology in 2021.</p> <p>I am dedicated to explore <strong>solving medical inverse problems</strong> within a scarce data and low SNR scenarios. Currently, my research focuses on:</p> <ul> <li>CT/MRI Undersampled Reconstruction <br> </li> <li>Motion Correction and Motion Tracking <br> </li> <li>Self-supervised Image Restoration <br> </li> <li>Diffusion Models</li> </ul> <p>See more in the <a href="https://MeijiTian.github.io/assets/pdf/XuanyuTian.pdf" target="_blank" rel="noopener noreferrer">detailed CV</a>.</p> </div> <div class="news"> <h2>News</h2> <div class="table-responsive" style="max-height: 275px"> <table class="table table-sm table-borderless"> <tr> <th scope="row" width="20%"><b>Feb 12, 2025</b></th> <td width="75%"> Our paper “Moner” will be presented as a <strong>Spotlight</strong> at ICLR 2025 <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> </td> </tr> <tr> <th scope="row" width="20%"><b>Feb 9, 2025</b></th> <td width="75%"> One paper about motion correction and coil sensitivity of parallel mri was accepted by <strong>Medical Image Analysis</strong> <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> </td> </tr> <tr> <th scope="row" width="20%"><b>Jan 22, 2025</b></th> <td width="75%"> One paper was accepted by The 13th International Conference on Learning Representations <strong>ICLR 2025</strong> <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> </td> </tr> <tr> <th scope="row" width="20%"><b>Jan 4, 2025</b></th> <td width="75%"> Two paper were accepted by <strong>IEEE ISBI 2025</strong> <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> </td> </tr> <tr> <th scope="row" width="20%"><b>Dec 27, 2024</b></th> <td width="75%"> One paper about high-dimensional MRI denoising was accepted by the <strong>Biomedical Signal Processing and Control (BSPC)</strong> <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> </td> </tr> <tr> <th scope="row" width="20%"><b>Dec 10, 2024</b></th> <td width="75%"> One paper about unsupervised sparse-view CT reconstruction was accepted by the 39th Annual AAAI Conference on Artificial Intelligence <strong>AAAI 2025</strong> <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> </td> </tr> <tr> <th scope="row" width="20%"><b>Nov 29, 2024</b></th> <td width="75%"> One paper was accepted by <strong>Medical Image Analysis</strong> <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> </td> </tr> <tr> <th scope="row" width="20%"><b>Oct 6, 2024</b></th> <td width="75%"> I attended MICCAI 2024 at Marrakech in Morocco. A Legendary Journey <img class="emoji" title=":smiley:" alt=":smiley:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f603.png" height="20" width="20"> </td> </tr> <tr> <th scope="row" width="20%"><b>Sep 5, 2024</b></th> <td width="75%"> One paper was accepted by IEEE Transactions on Compuational Imaging (IEEE TCI) <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> </td> </tr> <tr> <th scope="row" width="20%"><b>May 14, 2024</b></th> <td width="75%"> One paper was accepted by MICCAI 2024 <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> </td> </tr> <tr> <th scope="row" width="20%"><b>Feb 3, 2024</b></th> <td width="75%"> One paper was accepted by IEEE ISBI 2024 <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> </td> </tr> <tr> <th scope="row" width="20%"><b>Mar 2, 2023</b></th> <td width="75%"> One paper was accepted by IEEE ISBI 2023 <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> </td> </tr> <tr> <th scope="row" width="20%"><b>Sep 18, 2022</b></th> <td width="75%"> One paper was accepted by MICCAI 2022 <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> </td> </tr> <tr> <th scope="row" width="20%"><b>Sep 1, 2021</b></th> <td width="75%"> Join <a href="https://smilelab.com.cn/" target="_blank" rel="noopener noreferrer">SMILE lab</a> at ShanghaiTech University <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> </td> </tr> </table> </div> </div> <div class="publications"> <h2>Selected Publications</h2> <h6>* denotes the co-first author</h6> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-3 " style="text-align:center"> <abbr class="badge" style="background: var(--global-theme-color);border-style: solid;border-width: 2px;border-color:var(--global-theme-color)"> <div style="color:var(--global-bg-color);">MedIA 2025</div></abbr><br><p></p> <img id="JSMoCopng" class="preview z-depth-1 rounded myImg" src="/assets/img/publication_preview/JSMoCo.png"><div id="JSMoCopng-modal" class="modal2"> <span class="closeimg" onclick="document.getElementById('JSMoCopng-modal').style.display='none'">×</span> <div class="myCaption"></div> <img class="modal-content2" id="JSMoCopng-modal-img"> </div> <script>var modal=document.getElementById("JSMoCopng-modal"),img=document.getElementById("JSMoCopng"),modalImg=document.getElementById("JSMoCopng-modal-img"),captionText=modal.getElementsByTagName("div")[0];img.onclick=function(){modal.style.display="block",modalImg.src=this.src,captionText.innerHTML=""};var span=modal.getElementsByTagName("span")[0];span.onclick=function(){modal.style.display="none"},modal.onclick=function(){modal.style.display="none"};</script> </div> <div id="chen2025joint" class="col-sm-8"> <div class="title">Joint coil sensitivity and motion correction in parallel MRI with a self-calibrating score-based diffusion model</div> <div class="author"> <a href="https://maopaom.github.io/" target="_blank" rel="noopener noreferrer">Lixuan Chen*</a>,  <strong>Xuanyu Tian*</strong>, <a href="https://miraiwu.github.io/" target="_blank" rel="noopener noreferrer">Jiangjie Wu</a>, Ruimin Feng, Guoyan Lao, <a href="https://scholar.google.com/citations?user=gIE0JTAAAAAJ&amp;hl" target="_blank" rel="noopener noreferrer">Yuyao Zhang</a>, Hongen Liao, and <a href="https://scholar.google.com/citations?user=IORn-tEAAAAJ&amp;hl" target="_blank" rel="noopener noreferrer">Hongjiang Wei</a> </div> <div class="periodical"> <i>Medical Image Analysis</i> <i>2025</i> </div> <div class="links"> <a href="https://arxiv.org/abs/2310.09625" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/MeijiTian/JSMoCo" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 " style="text-align:center"> <abbr class="badge" style="background: var(--global-theme-color);border-style: solid;border-width: 2px;border-color:var(--global-theme-color)"> <div style="color:var(--global-bg-color);">AAAI 2025</div></abbr><br><p></p> <img id="Spenerpng" class="preview z-depth-1 rounded myImg" src="/assets/img/publication_preview/Spener.png"><div id="Spenerpng-modal" class="modal2"> <span class="closeimg" onclick="document.getElementById('Spenerpng-modal').style.display='none'">×</span> <div class="myCaption"></div> <img class="modal-content2" id="Spenerpng-modal-img"> </div> <script>var modal=document.getElementById("Spenerpng-modal"),img=document.getElementById("Spenerpng"),modalImg=document.getElementById("Spenerpng-modal-img"),captionText=modal.getElementsByTagName("div")[0];img.onclick=function(){modal.style.display="block",modalImg.src=this.src,captionText.innerHTML=""};var span=modal.getElementsByTagName("span")[0];span.onclick=function(){modal.style.display="none"},modal.onclick=function(){modal.style.display="none"};</script> </div> <div id="tian2025unsupervised" class="col-sm-8"> <div class="title">Unsupervised Self-Prior Embedding Neural Representation for Iterative Sparse-View CT Reconstruction</div> <div class="author"> <strong>Xuanyu Tian</strong>, <a href="https://maopaom.github.io/" target="_blank" rel="noopener noreferrer">Lixuan Chen</a>, <a href="https://iwuqing.github.io" target="_blank" rel="noopener noreferrer">Qing Wu</a>, Chenhe Du, Jingjing Shi, <a href="https://scholar.google.com/citations?user=IORn-tEAAAAJ&amp;hl" target="_blank" rel="noopener noreferrer">Hongjiang Wei</a>, and <a href="https://scholar.google.com/citations?user=gIE0JTAAAAAJ&amp;hl" target="_blank" rel="noopener noreferrer">Yuyao Zhang</a> </div> <div class="periodical"> <i> Proceedings of the AAAI Conference on Artificial Intelligence</i> <i>2025</i> </div> <div class="links"> <a href="https://github.com/MeijiTian/Spener" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 " style="text-align:center"> <abbr class="badge" style="background: var(--global-theme-color);border-style: solid;border-width: 2px;border-color:var(--global-theme-color)"> <div style="color:var(--global-bg-color);">ICLR 2025</div></abbr><br> <abbr class="badge" style="background: var(--global-bg-color);border-style: solid;border-width: 2px;border-color:var(--global-theme-color)"> <div style="color:var(--global-theme-color);">Spotlight</div></abbr><p></p> <img id="Monerpng" class="preview z-depth-1 rounded myImg" src="/assets/img/publication_preview/Moner.png"><div id="Monerpng-modal" class="modal2"> <span class="closeimg" onclick="document.getElementById('Monerpng-modal').style.display='none'">×</span> <div class="myCaption"></div> <img class="modal-content2" id="Monerpng-modal-img"> </div> <script>var modal=document.getElementById("Monerpng-modal"),img=document.getElementById("Monerpng"),modalImg=document.getElementById("Monerpng-modal-img"),captionText=modal.getElementsByTagName("div")[0];img.onclick=function(){modal.style.display="block",modalImg.src=this.src,captionText.innerHTML=""};var span=modal.getElementsByTagName("span")[0];span.onclick=function(){modal.style.display="none"},modal.onclick=function(){modal.style.display="none"};</script> </div> <div id="wu2024moner" class="col-sm-8"> <div class="title">Moner: Motion Correction in Undersampled Radial MRI with Unsupervised Neural Representation</div> <div class="author"> <a href="https://iwuqing.github.io" target="_blank" rel="noopener noreferrer">Qing Wu*</a>, Chenhe Du*,  <strong>Xuanyu Tian</strong>, Jingyi Yu, <a href="https://scholar.google.com/citations?user=gIE0JTAAAAAJ&amp;hl" target="_blank" rel="noopener noreferrer">Yuyao Zhang</a>, and <a href="https://scholar.google.com/citations?user=IORn-tEAAAAJ&amp;hl" target="_blank" rel="noopener noreferrer">Hongjiang Wei</a> </div> <div class="periodical"> <i>The 13th International Conference on Learning Representations</i> <i>2025</i> </div> <div class="links"> <a href="https://arxiv.org/abs/2409.16921" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 " style="text-align:center"> <abbr class="badge" style="background: var(--global-theme-color);border-style: solid;border-width: 2px;border-color:var(--global-theme-color)"> <div style="color:var(--global-bg-color);">MedIA 2024</div></abbr><br><p></p> <img id="Collatorgif" class="preview z-depth-1 rounded myImg" src="/assets/img/publication_preview/Collator.gif"><div id="Collatorgif-modal" class="modal2"> <span class="closeimg" onclick="document.getElementById('Collatorgif-modal').style.display='none'">×</span> <div class="myCaption"></div> <img class="modal-content2" id="Collatorgif-modal-img"> </div> <script>var modal=document.getElementById("Collatorgif-modal"),img=document.getElementById("Collatorgif"),modalImg=document.getElementById("Collatorgif-modal-img"),captionText=modal.getElementsByTagName("div")[0];img.onclick=function(){modal.style.display="block",modalImg.src=this.src,captionText.innerHTML=""};var span=modal.getElementsByTagName("span")[0];span.onclick=function(){modal.style.display="none"},modal.onclick=function(){modal.style.display="none"};</script> </div> <div id="chen2024collator" class="col-sm-8"> <div class="title">COLLATOR: Consistent spatial-temporal longitudinal atlas construction via implicit neural representation</div> <div class="author"> <a href="https://maopaom.github.io/" target="_blank" rel="noopener noreferrer">Lixuan Chen*</a>,  <strong>Xuanyu Tian*</strong>, <a href="https://miraiwu.github.io/" target="_blank" rel="noopener noreferrer">Jiangjie Wu</a>, Guoyan Lao, <a href="https://scholar.google.com/citations?user=gIE0JTAAAAAJ&amp;hl" target="_blank" rel="noopener noreferrer">Yuyao Zhang</a>, and <a href="https://scholar.google.com/citations?user=IORn-tEAAAAJ&amp;hl" target="_blank" rel="noopener noreferrer">Hongjiang Wei</a> </div> <div class="periodical"> <i>Medical Image Analysis</i> <i>2024</i> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.sciencedirect.com/science/article/pii/S1361841524003219" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/maopaom/COLLATOR" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="abstract hidden"> <p>Longitudinal brain atlases that present brain development trend along time, are essential tools for brain development studies. However, conventional methods construct these atlases by independently averaging brain images from different individuals at discrete time points. This approach could introduce temporal inconsistencies due to variations in ontogenetic trends among samples, potentially affecting accuracy of brain developmental characteristic analysis. In this paper, we propose an implicit neural representation (INR)-based framework to improve the temporal consistency in longitudinal atlases. We treat temporal inconsistency as a 4-dimensional (4D) image denoising task, where the data consists of 3D spatial information and 1D temporal progression. We formulate the longitudinal atlas as an implicit function of the spatial-temporal coordinates, allowing structural inconsistency over the time to be considered as 3D image noise along age. Inspired by recent self-supervised denoising methods (e.g. Noise2Noise), our approach learns the noise-free and temporally continuous implicit function from inconsistent longitudinal atlas data. Finally, the time-consistent longitudinal brain atlas can be reconstructed by evaluating the denoised 4D INR function at critical brain developing time points. We evaluate our approach on three longitudinal brain atlases of different MRI modalities, demonstrating that our method significantly improves temporal consistency while accurately preserving brain structures. Additionally, the continuous functions generated by our method enable the creation of 4D atlases with higher spatial and temporal resolution.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 " style="text-align:center"> <abbr class="badge" style="background: var(--global-theme-color);border-style: solid;border-width: 2px;border-color:var(--global-theme-color)"> <div style="color:var(--global-bg-color);">IEEE TCI 2024</div></abbr><br><p></p> <img id="ZSD-HREMpng" class="preview z-depth-1 rounded myImg" src="/assets/img/publication_preview/ZSD-HREM.png"><div id="ZSD-HREMpng-modal" class="modal2"> <span class="closeimg" onclick="document.getElementById('ZSD-HREMpng-modal').style.display='none'">×</span> <div class="myCaption"></div> <img class="modal-content2" id="ZSD-HREMpng-modal-img"> </div> <script>var modal=document.getElementById("ZSD-HREMpng-modal"),img=document.getElementById("ZSD-HREMpng"),modalImg=document.getElementById("ZSD-HREMpng-modal-img"),captionText=modal.getElementsByTagName("div")[0];img.onclick=function(){modal.style.display="block",modalImg.src=this.src,captionText.innerHTML=""};var span=modal.getElementsByTagName("span")[0];span.onclick=function(){modal.style.display="none"},modal.onclick=function(){modal.style.display="none"};</script> </div> <div id="tian2024zero" class="col-sm-8"> <div class="title">Zero-Shot Image Denoising for High-Resolution Electron Microscopy</div> <div class="author"> <strong>Xuanyu Tian</strong>, Zhuoya Dong, Xiyue Lin, Yue Gao, <a href="https://scholar.google.com/citations?user=IORn-tEAAAAJ&amp;hl" target="_blank" rel="noopener noreferrer">Hongjiang Wei</a>, Yanhang Ma, Jingyi Yu, and <a href="https://scholar.google.com/citations?user=gIE0JTAAAAAJ&amp;hl" target="_blank" rel="noopener noreferrer">Yuyao Zhang</a> </div> <div class="periodical"> <i>IEEE Transactions on Computational Imaging</i> <i>2024</i> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2406.14264.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/MeijiTian/ZS-Denoiser-HREM" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="abstract hidden"> <p>High-resolution electron microscopy (HREM) imaging technique is a powerful tool for directly visualizing a broad range of materials in real-space. However, it faces challenges in denoising due to ultra-low signal-to-noise ratio (SNR) and scarce data availability. In this work, we propose Noise2SR, a zero- shot self-supervised learning (ZS-SSL) denoising framework for HREM. Within our framework, we propose a super-resolution (SR) based self-supervised training strategy, incorporating the Random Sub-sampler module. The Random Sub-sampler is designed to generate approximate infinite noisy pairs from a single noisy image, serving as an effective data augmentation in zero-shot denoising. Noise2SR trains the network with paired noisy images of different resolutions, which is conducted via SR strategy. The SR-based training facilitates the network adopting more pixels for supervision, and the random sub-sampling helps compel the network to learn continuous signals enhancing the robustness. Meanwhile, we mitigate the uncertainty caused by random-sampling by adopting minimum mean squared error (MMSE) estimation for the denoised results. With the distinctive integration of training strategy and proposed designs, Noise2SR can achieve superior denoising performance using a single noisy HREM image. We evaluate the performance of Noise2SR in both simulated and real HREM denoising tasks. It outperforms state- of-the-art ZS-SSL methods and achieves comparable denoising performance with supervised methods. The success of Noise2SR suggests its potential for improving the SNR of images in material imaging domains.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 " style="text-align:center"> <abbr class="badge" style="background: var(--global-theme-color);border-style: solid;border-width: 2px;border-color:var(--global-theme-color)"> <div style="color:var(--global-bg-color);">MICCAI 2022</div></abbr><br><p></p> <img id="MICCAI2022_Noise2SRpng" class="preview z-depth-1 rounded myImg" src="/assets/img/publication_preview/MICCAI2022_Noise2SR.png"><div id="MICCAI2022_Noise2SRpng-modal" class="modal2"> <span class="closeimg" onclick="document.getElementById('MICCAI2022_Noise2SRpng-modal').style.display='none'">×</span> <div class="myCaption"></div> <img class="modal-content2" id="MICCAI2022_Noise2SRpng-modal-img"> </div> <script>var modal=document.getElementById("MICCAI2022_Noise2SRpng-modal"),img=document.getElementById("MICCAI2022_Noise2SRpng"),modalImg=document.getElementById("MICCAI2022_Noise2SRpng-modal-img"),captionText=modal.getElementsByTagName("div")[0];img.onclick=function(){modal.style.display="block",modalImg.src=this.src,captionText.innerHTML=""};var span=modal.getElementsByTagName("span")[0];span.onclick=function(){modal.style.display="none"},modal.onclick=function(){modal.style.display="none"};</script> </div> <div id="tian2022noise2sr" class="col-sm-8"> <div class="title">Noise2SR: Learning to Denoise from Super-Resolved Single Noisy Fluorescence Image</div> <div class="author"> <strong>Xuanyu Tian</strong>, <a href="https://iwuqing.github.io" target="_blank" rel="noopener noreferrer">Qing Wu</a>, <a href="https://scholar.google.com/citations?user=IORn-tEAAAAJ&amp;hl" target="_blank" rel="noopener noreferrer">Hongjiang Wei</a>, and <a href="https://scholar.google.com/citations?user=gIE0JTAAAAAJ&amp;hl" target="_blank" rel="noopener noreferrer">Yuyao Zhang</a> </div> <div class="periodical"> <i> Medical Image Computing and Computer Assisted Intervention</i> <i>2022</i> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://link.springer.com/chapter/10.1007/978-3-031-16446-0_32" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://arxiv.org/pdf/2209.06411.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>Fluorescence microscopy is a key driver to promote discoveries of biomedical research. However, with the limitation of microscope hardware and characteristics of the observed samples, the fluorescence microscopy images are susceptible to noise. Recently, a few self-supervised deep learning (DL) denoising methods have been proposed. However, the training efficiency and denoising performance of existing methods are relatively low in real scene noise removal. To address this issue, this paper proposed self-supervised image denoising method Noise2SR (N2SR) to train a simple and effective image denoising model based on single noisy observation. Our Noise2SR denoising model is designed for training with paired noisy images of different dimensions. Benefiting from this training strategy, Noise2SR is more efficiently self-supervised and able to restore more image details from a single noisy observation. Experimental results of simulated noise and real microscopy noise removal show that Noise2SR outperforms two blind-spot based self-supervised deep learning image denoising methods. We envision that Noise2SR has the potential to improve more other kind of scientific imaging quality.</p> </div> </div> </div> </li> </ol> </div> <div style="height: 20px;"></div> <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=7bdc63&amp;w=455&amp;t=tt&amp;d=W4z1yGOAg3zF5JlwMCP8ynZvG5HMCgCXnDi1m2GvtrA&amp;co=ffffff&amp;ct=1f9f00&amp;cmo=75afc2&amp;cmn=ff481f"></script> </article> </div> </div> </body></body></body> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> &copy; Copyright 2025 Xuanyu Tian.Last updated: March 05, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>